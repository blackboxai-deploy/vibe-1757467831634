#!/usr/bin/env python3
"""
Web Scraper para Comercio ElectrÃ³nico
Script completo para extraer precios y nombres de productos
Soporta Amazon, eBay, MercadoLibre y otros sitios

Uso:
    python web_scraper.py <URL>
    
Ejemplo:
    python web_scraper.py https://www.amazon.com/dp/B08N5WRWNW
"""

import json
import sys
import time
import argparse
from typing import Dict, Optional, Any
import requests
from bs4 import BeautifulSoup
from scraper_utils import ScrapingUtils

class EcommerceScraper:
    """
    Scraper principal para sitios de comercio electrÃ³nico
    """
    
    def __init__(self, timeout: int = 15, retries: int = 3):
        self.utils = ScrapingUtils()
        self.timeout = timeout
        self.retries = retries
        self.session = requests.Session()
        
    def scrape_product(self, url: str) -> Dict[str, Any]:
        """
        Scraper principal que extrae informaciÃ³n del producto
        
        Args:
            url: URL del producto a scrapear
            
        Returns:
            Dict con informaciÃ³n del producto o error
        """
        result = {
            'success': False,
            'url': url,
            'title': None,
            'price': None,
            'currency': None,
            'site': None,
            'error': None,
            'timestamp': int(time.time())
        }
        
        try:
            # Validar URL
            if not self.utils.validate_url(url):
                result['error'] = 'URL invÃ¡lida'
                return result
            
            # Extraer dominio
            domain = self.utils.extract_domain(url)
            result['site'] = domain
            
            # Obtener selectores para el sitio
            selectors = self.utils.get_site_selectors(domain)
            
            # Scraper con reintentos
            soup = None
            for attempt in range(self.retries):
                try:
                    soup = self._fetch_page(url)
                    if soup:
                        break
                except Exception as e:
                    if attempt == self.retries - 1:
                        result['error'] = f'Error al cargar pÃ¡gina: {str(e)}'
                        return result
                    # Wait before retry
                    time.sleep(self.utils.get_random_delay(1, 3))
            
            if not soup:
                result['error'] = 'No se pudo cargar la pÃ¡gina'
                return result
            
            # Extraer tÃ­tulo
            title = self._extract_element(soup, selectors.get('title', []))
            if title:
                result['title'] = self.utils.clean_text(title)
            
            # Extraer precio
            price_text = self._extract_element(soup, selectors.get('price', []))
            if price_text:
                cleaned_price = self.utils.clean_price(price_text)
                if cleaned_price:
                    result['price'] = cleaned_price
                    # Detectar moneda
                    result['currency'] = self._detect_currency(cleaned_price, domain)
            
            # Verificar si se encontrÃ³ informaciÃ³n bÃ¡sica
            if result['title'] or result['price']:
                result['success'] = True
            else:
                result['error'] = 'No se pudieron encontrar elementos del producto. Los selectores CSS pueden haber cambiado.'
                
        except Exception as e:
            result['error'] = f'Error inesperado: {str(e)}'
        
        return result
    
    def _fetch_page(self, url: str) -> Optional[BeautifulSoup]:
        """
        Descarga y parsea una pÃ¡gina web
        """
        headers = self.utils.get_random_headers()
        
        response = self.session.get(
            url,
            headers=headers,
            timeout=self.timeout,
            allow_redirects=True
        )
        
        response.raise_for_status()
        
        # Parse with BeautifulSoup
        soup = BeautifulSoup(response.content, 'lxml')
        return soup
    
    def _extract_element(self, soup: BeautifulSoup, selectors: list) -> Optional[str]:
        """
        Extrae texto usando mÃºltiples selectores CSS
        """
        for selector in selectors:
            try:
                element = soup.select_one(selector)
                if element:
                    text = element.get_text(strip=True)
                    if text and len(text.strip()) > 0:
                        return text
            except Exception:
                continue
        return None
    
    def _detect_currency(self, price_text: str, domain: str) -> Optional[str]:
        """
        Detecta la moneda basada en el precio y dominio
        """
        if '$' in price_text:
            if '.mx' in domain:
                return 'MXN'
            elif '.com.ar' in domain:
                return 'ARS'
            else:
                return 'USD'
        elif 'â‚¬' in price_text:
            return 'EUR'
        elif 'Â£' in price_text:
            return 'GBP'
        elif 'MXN' in price_text.upper():
            return 'MXN'
        elif 'EUR' in price_text.upper():
            return 'EUR'
        elif 'USD' in price_text.upper():
            return 'USD'
        else:
            # Inferir por dominio
            if '.mx' in domain or 'mercadolibre.com.mx' in domain:
                return 'MXN'
            elif '.com.ar' in domain:
                return 'ARS'
            elif '.es' in domain or '.fr' in domain or '.de' in domain:
                return 'EUR'
            else:
                return 'USD'

def print_formatted_result(result: Dict[str, Any]) -> None:
    """
    Imprime el resultado formateado en consola
    """
    print("=" * 60)
    print("ğŸ›’ RESULTADO DEL WEB SCRAPING")
    print("=" * 60)
    
    if result['success']:
        print(f"âœ… Ã‰XITO - InformaciÃ³n extraÃ­da correctamente")
        print(f"ğŸŒ Sitio: {result['site']}")
        print(f"ğŸ”— URL: {result['url']}")
        
        if result['title']:
            print(f"ğŸ“¦ Producto: {result['title']}")
        else:
            print(f"ğŸ“¦ Producto: No encontrado")
            
        if result['price']:
            currency_symbol = {
                'USD': '$',
                'EUR': 'â‚¬',
                'GBP': 'Â£',
                'MXN': '$',
                'ARS': '$'
            }.get(result['currency'], '')
            
            print(f"ğŸ’° Precio: {currency_symbol}{result['price']} {result['currency'] or ''}")
        else:
            print(f"ğŸ’° Precio: No encontrado")
            
    else:
        print(f"âŒ ERROR - No se pudo extraer informaciÃ³n")
        print(f"ğŸŒ Sitio: {result['site']}")
        print(f"ğŸ”— URL: {result['url']}")
        print(f"âš ï¸  Error: {result['error']}")
    
    print("=" * 60)

def main():
    """
    FunciÃ³n principal del script
    """
    parser = argparse.ArgumentParser(
        description='Web Scraper para extraer precios de productos de comercio electrÃ³nico'
    )
    parser.add_argument('url', help='URL del producto a scrapear')
    parser.add_argument('--timeout', type=int, default=15, help='Timeout en segundos (default: 15)')
    parser.add_argument('--retries', type=int, default=3, help='NÃºmero de reintentos (default: 3)')
    parser.add_argument('--json', action='store_true', help='Salida en formato JSON')
    
    args = parser.parse_args()
    
    # Crear scraper
    scraper = EcommerceScraper(timeout=args.timeout, retries=args.retries)
    
    print("ğŸš€ Iniciando web scraping...")
    print(f"ğŸ¯ URL objetivo: {args.url}")
    print("â³ Procesando...")
    
    # Ejecutar scraping
    result = scraper.scrape_product(args.url)
    
    # Mostrar resultado
    if args.json:
        print(json.dumps(result, ensure_ascii=False, indent=2))
    else:
        print_formatted_result(result)
    
    # Exit code basado en Ã©xito
    sys.exit(0 if result['success'] else 1)

if __name__ == "__main__":
    main()